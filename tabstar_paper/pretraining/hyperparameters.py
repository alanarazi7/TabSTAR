TABULAR_LAYERS = 6
WEIGHT_DECAY = 0.001
BASE_LR = 0.00005
TEXTUAL_UNFREEZE_LAYERS = 6
PRETRAIN_GLOBAL_BATCH_SIZE = 128